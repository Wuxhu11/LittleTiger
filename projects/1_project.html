<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Federated Learning | Xiaohu Wu </title> <meta name="author" content="Xiaohu Wu"> <meta name="description" content="Free-riding, market competition, collaboration formation, measuring data heterogeneity, personalization, multi-task learning, federated foundation models"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://wuxhu11.github.io/projects/1_project.html"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Xiaohu</span> Wu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/papers/">Papers </a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">Research </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Team </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Funding </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">Services </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Federated Learning</h1> <p class="post-description">Free-riding, market competition, collaboration formation, measuring data heterogeneity, personalization, multi-task learning, federated foundation models</p> </header> <article> <h3 id="table-of-contents"><strong>Table of Contents</strong></h3> <ol> <li><a href="#FL">Cross-silo federated learning</a></li> <li><a href="#overview">An overview of my research</a></li> <li><a href="#part1">Conlfict resolution: Competition, free-riding, and collaboration</a></li> <li><a href="#part2">Quantifying benefit strength via multi-task learning</a></li> <li><a href="#part3">Personalized federated learning</a></li> <li><a href="#part4">Federated foundation models</a></li> </ol> <blockquote> <h3 id="1-cross-silo-federated-learning-fl"><strong>1. Cross-silo Federated Learning (FL)</strong></h3> <p><a id="FL"></a></p> </blockquote> <p>In FL, a central server (CS) periodically gathers model updates from individual FL participants (i.e., clients), which are then aggregated to refne a global model. Similarly, each client regularly acquires the latest global model from the CS and further enhances it through local training. This iterative interplay between the CS and clients persists until the global model achieves convergence.</p> <p>There are two types of FL. In <em>cross-device FL</em>, clients are end-user devices such as smartphones or IoT devices, and CS is the final owner of the trained model. In <em>cross-silo FL</em>, client are companies or organizations in private or public sectors and are the final owners/users of the trained model, while the CS has the authority to coordinate the FL training process.</p> <blockquote> <h3 id="2-an-overview-of-my-research"><strong>2. An Overview of My Research</strong></h3> <p><a id="overview"></a></p> </blockquote> <div style="float: right; margin-left: 20px; width: 45%;"> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/research-overview-2-480.webp 480w,/assets/img/research-overview-2-800.webp 800w,/assets/img/research-overview-2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/research-overview-2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> An Overview of My Research. </div> </div> <p>Data heterogeneity among clients somewhat reflects their data complementarity. FL itself is a collaborative network of clients where a client $i$ is complemented by other clients $j$ with different weights $w_{i,j}$. One basic way that FL works is to aggregate the clients’ local model updates according to their weights. In cross-silo FL, clients are typically organizations or companies in the public or private sector. Wihout proper design, such collaborative networks can feature conflict of interest between clients (e.g., <a href="https://en.wikipedia.org/wiki/Coopetition" rel="external nofollow noopener" target="_blank">competition</a>) and <a href="https://en.wikipedia.org/wiki/Free-rider_problem" rel="external nofollow noopener" target="_blank">free-riding</a>. Data heterogeneity entails evaluating the client weights effectively and building a personalized FL model for each client.</p> <p>It is predicted that, by around 2028, the amount of high-quality data that LLMs will require to continue to improve their performance will exceed what is publicly available. This amplifies the importance of FL, which enables collaborative model training across distributed private data sources without sharing raw data.</p> <p>Currently, I focus on how to build a collaborative network of multiple clients, and the questions of my study include:</p> <ol> <li>Free-riding, competition, and collaboration <a class="citation" href="#Wu24a">(Wu &amp; Yu, 2024; Tan<em>† et al., 2024; Chen</em> et al., 2024)</a> </li> <li>Quantifying data heterogeneity/complementarity <a class="citation" href="#chenvoronoi">(Chen<em>† et al., 2025; Li</em> et al., 2024)</a> </li> <li>Personalized federated learning <a class="citation" href="#Liu25a">(Liu et al., 2025; Guo et al., 2024)</a> </li> <li>Federated foundation models</li> </ol> <p>The first three questions are key to building an FL ecosystem in the case where clients are self-interested organizations or companies, while the fourth question is also important in the era of foundation models.</p> <blockquote> <h3 id="3-conlfict-resolution-competition-free-riding-and-collaboration"><strong>3. Conlfict resolution: Competition, Free-riding, and Collaboration</strong></h3> <p><a id="part1"></a></p> </blockquote> <p><span style="color: purple;">A series of our works initiated and advanced research of federated learning when competition exists between clients</span>, which is important since self-interested companies from the private sector are a key source of clients in cross-silo FL.</p> <blockquote> <h4 id="31-full-competition-between-clients"><strong>3.1 Full competition between clients</strong></h4> </blockquote> <div style="float: right; margin-left: 20px; width: 42%;"> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Fig-FL-Compete-480.webp 480w,/assets/img/Fig-FL-Compete-800.webp 800w,/assets/img/Fig-FL-Compete-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/Fig-FL-Compete.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> All clients are in the same market area. </div> </div> <p>We are <span style="color: blue;">the first to consider the case that all clients compete against each other</span> <a class="citation" href="#Wu24a">(Wu &amp; Yu, 2024)</a>. This occurs when all clients are in the same market area and provide the same service or product. In our study, we aim to maintain a negligible change in market share after clients join the FL ecosystem, and analyze the achievability of this objective. The classic marketing model of Rust \&amp; Zahorik (1993) is used to model the market dynamics. We characterize the effect of FL on the model performance and the service quality of each client, which further affects the attractiveness of the service provided by this client.</p> <p>Formally, we introduce two notions of $\delta$-stable market and friendliness to measure the viability of FL and the market acceptability of FL. The client behaviours can be predicted using game theoretic tools (i.e., their optimal strategies concerning participation in FL). If the market $\delta$-stability is achievable, the final model performance improvement of each client shall be bounded, which relates to the market conditions of FL applications. We provide tight bounds and quantify the friendliness, $\kappa$, of given market conditions to FL. Experimental results show the viability of FL in a wide range of market conditions.</p> <hr> <blockquote> <h4 id="32-partial-competition-between-clients"><strong>3.2 Partial competition between clients</strong></h4> </blockquote> <div style="float: right; margin-left: 20px; width: 33%;"> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/hospitals-480.webp 480w,/assets/img/hospitals-800.webp 800w,/assets/img/hospitals-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/hospitals.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Clients are in multiple market areas. </div> </div> <p>We are also <span style="color: blue;">the first to consider the case that competition exists only in certain clients, rather than universally between any two clients</span> <a class="citation" href="#Tan24a">(Tan*† et al., 2024)</a>. This occurs when organizations compete for the same population within a market area while others operate in different market areas. For example, hospitals can be clients and aim at improving public health. The hospital in city $C$ focuses exclusively on improving its own ML model, and its utility is independent of any client in other cities. Hospitals within the same city (e.g., city $B$) serve the same population; competition arises since these hospitals compete for patients and a hospital’s utility is inversely proportional to another hospital’s model performance.</p> <div style="float: right; margin-left: 20px; width: 33%;"> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Collaboration-Principle-480.webp 480w,/assets/img/Collaboration-Principle-800.webp 800w,/assets/img/Collaboration-Principle-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/Collaboration-Principle.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Collaboration principle: clients $i$ and $j$ compete; the solid arrow $x\rightarrow y$ indicates that client $y$ will utilize the model update information of $x$ in the FL training process. </div> </div> <p>In this case, we extend the principle that “the friend of my enemy is my enemy” to construct the collboration relationship in the FL training propcess. Suppose clients $i$ and $j$ compete against each other. As illustrated in the right figure, client $i$ does not want to see others help its enemy $j$ and its enemy’s friends. We give a polynomial-time heuristic algorithm to construct the collaboration relationships of clients that follow this extended principle <a class="citation" href="#Tan24a">(Tan*† et al., 2024)</a>.</p> <p>In our recent work, we enhance the the work of <a class="citation" href="#Tan24a">(Tan*† et al., 2024)</a> by further incorporating concepts from Nash equilibrium to ensure each participant can achieve the best possible outcome without self-sacrifice - a critical feature desired by individuals in such systems. It reformulates the problem as a bi-level optimization and establishes conditions for optimal solutions through a novel application of topological dominance. Extensive experiments demonstrate the fairness and robustness of the proposed solution. This extended version will be submitted soon:</p> <ul> <li> <span style="color: blue;">Xiaohu Wu</span>, Han Yu, Mengmeng Chen, Tiantian He, Yew-Soon Ong, Qicheng Lao, Giuliano Casale. “Federated Learning with Competing Participants: Achieving Harmonious Collaboration with Minimal Self-Sacrifice.” To be submitted to JMLR.</li> </ul> <hr> <blockquote> <h4 id="33-free-riding-and-partial-competition"><strong>3.3 Free-riding, and partial competition</strong></h4> </blockquote> <p>Free-riding occurs when a client benefits from the contribution of other clients without making any contribution to the FL ecosystem. We consider both free-riding and partial competition among clients. Two principles are simultaneously used to meet the individual’s needs in such FL ecosystems: (1) a client can benefit from the FL ecosystem if and only if this client can benefit the FL ecosystem, and (2) a client will not contribute to its competitors as well as the allies of its competitors.</p> <div align="center"> <div style="width: 86%;"> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Free-riding-480.webp 480w,/assets/img/Free-riding-800.webp 800w,/assets/img/Free-riding-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/Free-riding.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> The main idea. </div> </div> </div> <p>We seek a proper problem formulation such that the resulting solution can well satisfy the clients’ needs and help them achieve the best possible ML model performances. All clients are partitioned into disjoint groups/coalitions, each with the common interest. We use theoretical tools from graph theory and propose an efficient solution, called FedEgoists, that can well satisfy the two principles above. Meanwhile, FedEgoists can help clients achieve the best possible ML model performances, i.e., subject to the two principles, the coalitions that FedEgoists finds are optimal in the sense that one coalition cannot increase the utility of any of its members by collaborating with any other coalitions <a class="citation" href="#chenvoronoi">(Chen*† et al., 2025)</a>.</p> <blockquote> <h3 id="4-quantifying-benefit-strength-via-multi-task-learning"><strong>4. Quantifying benefit strength via multi-task learning</strong></h3> <p><a id="part2"></a></p> </blockquote> <div style="float: right; margin-left: 20px; width: 28%;"> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/PHN-480.webp 480w,/assets/img/PHN-800.webp 800w,/assets/img/PHN-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/PHN.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> A Pareto Hypernetwork $h(\cdot; \phi)$ receives an input preference ray $r$ and outputs the corresponding model parameters $\theta_{r}$. </div> </div> <p>Multi-objective optimization (MOO) exists extensively in machine learning, and aims to find a set of Pareto-optimal solutions, called the Pareto front, e.g., it is fundamental for multiple avenues of research in federated learning (FL). Pareto Front Learning (PFL) is a powerful method implemented using Hypernetworks (PHNs) to approximate the Pareto front. This method enables the acquisition of a mapping function from a given preference vector to the solutions on the Pareto front. However, most existing PFL approaches still face two challenges: (a) sampling rays in high-dimensional spaces; (b) failing to cover the entire Pareto Front which has a convex shape. Here, we introduce a novel PFL framework, called as PHN-HVVS, which decomposes the design space into Voronoi grids and deploys a genetic algorithm (GA) for Voronoi grid partitioning within high-dimensional space <a class="citation" href="#chenvoronoi">(Chen*† et al., 2025)</a>. We put forward a new loss function, which effectively contributes to more extensive coverage of the resultant Pareto front and maximizes the HV Indicator. Experimental results on multiple MOO machine learning tasks demonstrate that PHN-HVVS outperforms the baselines significantly in generating Pareto front. Also, we illustrate that PHN-HVVS advances the methodologies of several recent problems in the FL field.</p> <blockquote> <h3 id="5-personalized-federated-learning-pfl"><strong>5. Personalized Federated Learning (pFL)</strong></h3> <p><a id="part3"></a></p> </blockquote> <p>A client $i$ is complemented by other clients $j$ with different weights $w_{i,j}$. One basic way of designing pFL schemes is to aggregate the clients’ local model updates according to their weights or data similarity.</p> <blockquote> <h4 id="51-a-data-similarity-based-approach"><strong>5.1 A data-similarity-based approach</strong></h4> </blockquote> <div align="center"> <div style="width: 86%;"> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/FedSimSup-480.webp 480w,/assets/img/FedSimSup-800.webp 800w,/assets/img/FedSimSup-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/FedSimSup.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> The framework of FedSimSup. </div> </div> </div> <p>A crucial issue in federated learning is the heterogeneity of data across clients, which may lead to model divergence, eventually deteriorating the model performance. Personalized federated learning (pFL) has been shown to be an effective approach to addressing data heterogeneity in federated learning. However, many existing pFL studies rely on directly using the global model for local training without fully assessing its impact on the performance of the local model, resulting in a potential conflict between personalization and generalization. To address this issue, we propose a parallel structure of a local supervisor and an inter-learning model for the local model and introduce a novel pFL method called federated learning by considering data similarity across clients assisted by a local supervisor (FedSimSup). Specifically, FedSimSup maintains an inter-learning model for each client and refines the inter-learning model using a local supervisor for each client. The local supervisor monitors the aggregated global information and ensures that the inter-learning model aligns with the local heterogeneous data to enhance local model performance. Additionally, the similarity between clients is measured based on differences in local data distributions, and this similarity is used to adjust the weights of the inter-learning models. Experimental results show that FedSimSup outperforms eight state-of-the-art federated learning methods in handling heterogeneous data. Additionally, it supports different model architectures across clients, providing greater flexibility when computational resources vary among them. Please see <a class="citation" href="#Liu25a">(Liu et al., 2025)</a> for the details.</p> <blockquote> <h4 id="52-a-benchmarking-study-of-statistical-heterogeneity"><strong>5.2 A benchmarking study of statistical heterogeneity</strong></h4> </blockquote> <p>There is growing research interest in measuring the statistical heterogeneity of clients’ local datasets for personalized federated learning (pFL) models. Currently, these research endeavors are taking place in silos. We develop a comprehensive benchmark to study these various approaches <a class="citation" href="#Li24a">(Li* et al., 2024)</a>. Our main contributions are as follows. Firstly, we summarize the six techniques (JS divergence, C-divergence, distribution sketch-based euclidean distance, Shapley Value, Hypernetworks, cosine similarity) into a unified framework to understand their application in FL settings. The unified framework clarifies the ways of quantifying the collaboration advantages among clients and the theoretical development of using collaboration advantages or data similarity for pFL. Secondly, we evaluate all six approaches under five standard Non-IID settings summarized in across eight widely-adopted benchmark datasets. We assess the performance of each approach in terms of computation cost, communication overhead and scalability. The results provide insights into which approaches are advantageous under which settings. Thirdly, the unified framework and the experimental results identify scenarios where the current approaches perform relatively poorly, highlighting promising future research directions for collaborative pFL. The study here motivates our work in <a class="citation" href="#chenvoronoi">(Chen*† et al., 2025; Liu et al., 2025)</a>.</p> <div style="float: right; margin-left: 20px; width: 42%;"> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/pFedGraph-480.webp 480w,/assets/img/pFedGraph-800.webp 800w,/assets/img/pFedGraph-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/pFedGraph.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> The main idea of pFedGAT. </div> </div> <blockquote> <h4 id="53-pfedgat-an-approach-using-graph-neural-networks"><strong>5.3 pFedGAT: An approach using graph neural networks</strong></h4> </blockquote> <p>Building on our previous work on graph neural networks (GNNs) <a class="citation" href="#he2024polarized">(He et al., 2024)</a> , my collaborators and I have also proposed a pFL scheme where the weights are learned by GNNs, which is currently under reivew:</p> <ul> <li>Ziran Zhou, Guanyu Gao, <span style="color: blue;">Xiaohu Wu</span>, Yan Lyu. “pFedGAT:Personalized Federated Learning with Graph Attention Network.” Submitted.</li> </ul> <blockquote> <h3 id="6-federated-foundation-models"><strong>6. Federated foundation models</strong></h3> <p><a id="part4"></a></p> </blockquote> <div align="center"> <div style="width: 86%;"> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/SFedLoRA-480.webp 480w,/assets/img/SFedLoRA-800.webp 800w,/assets/img/SFedLoRA-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/SFedLoRA.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> The framework of SFed-LoRA. </div> </div> </div> <p>Large Language Models (LLMs) have become pivotal in natural language processing. Traditional full fine-tuning is impractical, prompting the adoption of Parameter-Efficient Fine-Tuning (PEFT) methods like Low-Rank Adaptation (LoRA), which reduces trainable parameters using low-rank matrices $A$ and $B$. However, in real-world scenarios with distributed data across institutions, privacy constraints necessitate Federated Learning (FL), with recent integrations like FedIT exploring LoRA in this context. Despite progress, the stability of LoRA-based fine-tuning in federated settings remains challenged by gradient collapse at higher ranks, a limitation of the conventional scaling factor $\gamma_r = \frac{\alpha}{r}$, even with improvements from rsLoRA ($\gamma_r = \frac{\alpha}{\sqrt{r}}$) in standalone settings. This paper introduces Stabilized Federated LoRA (SFed-LoRA), a novel framework that enhances the stability and performance of LoRA fine-tuning in federated environments. We propose an optimal scaling factor $\gamma_z = \alpha\sqrt{\frac{N}{r}}$, derived theoretically to counteract aggregation-induced instability across $N$ clients. SFed-LoRA preserves LoRA’s adapter structure without increasing inference latency, offering a robust solution to mitigate federated aggregation effects. Extensive experiments demonstrate the superiority of our method in achieving stable, high-performance LLM fine-tuning.</p> <ul> <li>Jiayu Huang (<span style="color: blue;">my student</span>), Xiaohu Wu, Qicheng Lao, Guanyu Gao, Tiantian He, Yew-Soon Ong, Han Yu. “Stabilized Fine-Tuning with LoRA in Federated Learning: Mitigating the Side Effect of Client Size and Rank via the Scaling Factor.” Submitted.</li> </ul> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00d1da"> <div>ICML</div> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/federated-learning.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="federated-learning.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="chenvoronoi" class="col-sm-8"> <div class="title">Voronoi-grid-based Pareto Front Learning and Its Application to Collaborative Federated Learning</div> <div class="author"> Mengmeng Chen<sup>*†</sup>, <em>Xiaohu Wu<sup>†</sup></em>, Qiqi Liu, Tiantian He, Yew-Soon Ong, Yaochu Jin, Qicheng Lao, and Han Yu </div> <div class="periodical"> <em>The 42nd International Conference on Machine Learning</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"><font color="red">CCF A, CORE A*</font></a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="award hidden d-print-inline"> <p> </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">chenvoronoi</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Voronoi-grid-based Pareto Front Learning and Its Application to Collaborative Federated Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Mengmeng and Wu, Xiaohu and Liu, Qiqi and He, Tiantian and Ong, Yew-Soon and Jin, Yaochu and Lao, Qicheng and Yu, Han}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{The 42nd International Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00d1da"> <div>ICCV</div> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/federated-learning.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="federated-learning.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Liu25a" class="col-sm-8"> <div class="title">Personalized Federated Learning under Local Supervision</div> <div class="author"> Qiqi Liu, Jiaqiang Li, Yuchen Liu, Yaochu Jin, Lingjuan Lyu, <em>Xiaohu Wu</em>, and Han Yu </div> <div class="periodical"> <em>International Conference on Computer Vision</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"><font color="red">CCF A, CORE A*</font></a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="award hidden d-print-inline"> <p> </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Liu25a</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Personalized Federated Learning under Local Supervision}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Qiqi and Li, Jiaqiang and Liu, Yuchen and Jin, Yaochu and Lyu, Lingjuan and Wu, Xiaohu and Yu, Han}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{International Conference on Computer Vision}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">IEEE TBD</abbr> <figure> <picture> <img src="/assets/img/publication_preview/federated-learning.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="federated-learning.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Wu24a" class="col-sm-8"> <div class="title">MarS-FL: Enabling Competitors to Collaborate in Federated Learning</div> <div class="author"> <em>Xiaohu Wu</em> and Han Yu </div> <div class="periodical"> <em>IEEE Transactions on Big Data</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"><font color="red">CCF C, IF 5.7</font></a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="award hidden d-print-inline"> <p> </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Wu24a</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu, Xiaohu and Yu, Han}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Big Data}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{MarS-FL: Enabling Competitors to Collaborate in Federated Learning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{801-811}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00d1da"> <div>AAAI</div> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/federated-learning.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="federated-learning.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Tan24a" class="col-sm-8"> <div class="title">Fedcompetitors: Harmonious collaboration in federated learning with competing participants</div> <div class="author"> Shanli Tan<sup>*†</sup>, Hao Cheng<sup>†</sup>, <em>Xiaohu Wu<sup>†</sup></em>, Han Yu<sup>†</sup>, Tiantian He, Yew Soon Ong, Chongjun Wang, and Xiaofeng Tao </div> <div class="periodical"> <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"><font color="red">CCF A, CORE A*</font></a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="award hidden d-print-inline"> <p> </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Tan24a</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fedcompetitors: Harmonious collaboration in federated learning with competing participants}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tan, Shanli and Cheng, Hao and Wu, Xiaohu and Yu, Han and He, Tiantian and Ong, Yew Soon and Wang, Chongjun and Tao, Xiaofeng}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proceedings of the AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{38}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{14}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{15231--15239}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00d1da"> <div>NeurIPS</div> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/federated-learning.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="federated-learning.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="chen2024free" class="col-sm-8"> <div class="title">Free-rider and conflict aware collaboration formation for cross-silo federated learning</div> <div class="author"> Mengmeng Chen<sup>*</sup>, <em>Xiaohu Wu</em>, Xiaoli Tang, Tiantian He, Yew Soon Ong, Qiqi Liu, Qicheng Lao, and Han Yu </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"><font color="red">CCF A, CORE A*</font></a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="award hidden d-print-inline"> <p> </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">chen2024free</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Free-rider and conflict aware collaboration formation for cross-silo federated learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Mengmeng and Wu, Xiaohu and Tang, Xiaoli and He, Tiantian and Ong, Yew Soon and Liu, Qiqi and Lao, Qicheng and Yu, Han}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{37}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{54974--55004}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Curran Associates Inc.}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#a0bbc1"> <div>Book Chapter</div> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/federated-learning.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="federated-learning.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Li24a" class="col-sm-8"> <div class="title">Benchmarking Data Heterogeneity Evaluation Approaches for Personalized Federated Learning</div> <div class="author"> Zhilong Li<sup>*</sup>, <em>Xiaohu Wu</em>, Xiaoli Tang, Tiantian He, Yew-Soon Ong, Mengmeng Chen, Qiqi Liu, Qicheng Lao, and Han Yu </div> <div class="periodical"> <em>In Federated Learning in the Age of Foundation Models - FL 2024 International Workshops</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@incollection</span><span class="p">{</span><span class="nl">Li24a</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Zhilong and Wu, Xiaohu and Tang, Xiaoli and He, Tiantian and Ong, Yew-Soon and Chen, Mengmeng and Liu, Qiqi and Lao, Qicheng and Yu, Han}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Yu, Han and Li, Xiaoxiao and Xu, Zenglin and Goebel, Randy and King, Irwin}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Benchmarking Data Heterogeneity Evaluation Approaches for Personalized Federated Learning}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Federated Learning in the Age of Foundation Models - FL 2024 International Workshops}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer Nature Switzerland}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Cham}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{77--92}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-031-82240-7}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#a0bbc1"> <div>Book Chapter</div> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/federated-learning.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="federated-learning.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Guo24a" class="col-sm-8"> <div class="title">Enhancing Causal Discovery in Federated Settings with Limited Local Samples</div> <div class="author"> Xianjie Guo, Liping Yi, <em>Xiaohu Wu</em>, Kui Yu, and Gang Wang </div> <div class="periodical"> <em>In Federated Learning in the Age of Foundation Models - FL 2024 International Workshops</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"><font color="Blue">Outstanding Student Paper Award</font></a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>We receveid the <strong>Outstanding Student Paper Award</strong> at the NeurIPS 2024 workshop on federated foundation models.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@incollection</span><span class="p">{</span><span class="nl">Guo24a</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Guo, Xianjie and Yi, Liping and Wu, Xiaohu and Yu, Kui and Wang, Gang}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Yu, Han and Li, Xiaoxiao and Xu, Zenglin and Goebel, Randy and King, Irwin}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Enhancing Causal Discovery in Federated Settings with Limited Local Samples}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Federated Learning in the Age of Foundation Models - FL 2024 International Workshops}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer Nature Switzerland}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Cham}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{164--179}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-031-82240-7}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00d1da"> <div>AIJ</div> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/neural-network-v2.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="neural-network-v2.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="he2024polarized" class="col-sm-8"> <div class="title">Polarized message-passing in graph neural networks</div> <div class="author"> Tiantian He, Yang Liu, Yew-Soon Ong, <em>Xiaohu Wu</em>, and Xin Luo </div> <div class="periodical"> <em>Artificial Intelligence</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"><font color="red">CCF A, CORE A*</font></a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="award hidden d-print-inline"> <p> </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">he2024polarized</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Polarized message-passing in graph neural networks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{He, Tiantian and Liu, Yang and Ong, Yew-Soon and Wu, Xiaohu and Luo, Xin}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{331}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{104129}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Xiaohu Wu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>